{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Italian Manuscripts OCR with Kraken\n",
    "\n",
    "This notebook documents the end-to-end process used to create and fine-tune a Kraken OCR model for Italian handwritten manuscripts. It follows the same logical structure of the LaTeX report:\n",
    "\n",
    "- Preparation of line images and Markdown transcriptions\n",
    "- Generation and normalization of the ground truth file\n",
    "- Creation of train/validation/test splits and charset\n",
    "- Image preprocessing pipeline\n",
    "- Creation of sidecar `.gt.txt` files\n",
    "- Final training command for Kraken via `ketos`\n",
    "\n",
    "The notebook is mainly about **reproducibility and documentation**. Some paths and commands are taken from the original environment and may need to be adapted to your own directory layout and platform.\n",
    "\n",
    "In this version, the code is **more heavily commented** to clarify both:\n",
    "- **what** each block does (step by step), and\n",
    "- **why** it is needed in the context of building a Kraken model for Italian manuscripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment and prerequisites\n",
    "\n",
    "The work was carried out on a Linux machine (Pop!_OS) with an NVIDIA GPU and CUDA support. The following assumptions are made:\n",
    "\n",
    "- You have a working Python 3 environment (e.g. via `conda`).\n",
    "- `kraken` and `ketos` are installed in this environment (e.g. `pip install kraken`).\n",
    "- You have the following directory structure (or equivalent):\n",
    "  - `00_images/` – line images extracted from scanned pages (after ScanTailor or similar tools)\n",
    "  - `01_texts/` – Markdown files with manual transcriptions, one per line image\n",
    "  - `gt_new/` – folder where ground truth files will be written\n",
    "  - `splits_new/` – folder for train/val/test splits\n",
    "  - `processed/lines/` – folder for preprocessed line images used for training\n",
    "\n",
    "The main goal is to go from **raw scans + Markdown transcriptions** to a dataset that Kraken/ketos can use to fine‑tune an OCR model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generating ground truth from Markdown files\n",
    "\n",
    "We start from:\n",
    "- `00_images/` containing line images (e.g. `100_page1_line001.png`)\n",
    "- `01_texts/` containing Markdown transcriptions with matching stems (e.g. `100_page1_line001.md`)\n",
    "\n",
    "The script `make_gt_from_line_md.py` generates a tab-separated `ground_truth.txt` where each line contains:\n",
    "\n",
    "```text\n",
    "<image_path>\\t<normalized_plain_text>\n",
    "```\n",
    "\n",
    "### Why this step?\n",
    "\n",
    "Kraken/ketos expects a **ground truth file** that links each image to its textual transcription. Your transcriptions are more convenient to edit and read in Markdown, but for training we need **plain text without formatting**. This script:\n",
    "\n",
    "- finds, for each image, the corresponding `.md` (or `.txt` etc.) file;\n",
    "- strips Markdown formatting (links, emphasis, headers...);\n",
    "- optionally joins multiple lines into a single line of text;\n",
    "- writes one line per image, with path and transcription separated by a tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "bash"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Generate ground truth from Markdown transcriptions.\n",
    "#\n",
    "# This command scans:\n",
    "#   - ./00_images  for line images\n",
    "#   - ./01_texts   for corresponding .md files\n",
    "# and writes a tab-separated file gt_new/ground_truth_new.txt.\n",
    "#\n",
    "# You should adjust the paths if your project lives in a different directory layout.\n",
    "\n",
    "python3 make_gt_from_line_md.py \\\n",
    "    --images_dir \"./00_images\" \\\n",
    "    --md_dir \"./01_texts\" \\\n",
    "    --out \"gt_new/ground_truth_new.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# make_gt_from_line_md.py\n",
    "#\n",
    "# PURPOSE\n",
    "# -------\n",
    "# Build a ground truth file in the format expected by Kraken/ketos:\n",
    "#\n",
    "#   <image_path>\\t<plain_text_transcription>\n",
    "#\n",
    "# starting from:\n",
    "#   - a directory of images (one image per line of text)\n",
    "#   - a directory of Markdown files with the same stems as the images.\n",
    "#\n",
    "# This allows you to keep your human-readable transcriptions in Markdown,\n",
    "# while still producing the simple text format needed for OCR training.\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import unicodedata\n",
    "import re\n",
    "import sys\n",
    "\n",
    "def strip_markdown(s: str) -> str:\n",
    "    \"\"\"Remove basic Markdown constructs from a string.\n",
    "\n",
    "    This is *not* a full Markdown parser, but it's enough for typical\n",
    "    line-level transcriptions:\n",
    "    - remove images:           ![alt](url)\n",
    "    - unwrap links:            [text](url) -> text\n",
    "    - remove inline markers:   `code`, *emphasis*, _emphasis_\n",
    "    - remove leading > in quotes\n",
    "    - collapse whitespace.\n",
    "    \"\"\"\n",
    "    # Remove images\n",
    "    s = re.sub(r'!\\[.*?\\]\\(.*?\\)', '', s)\n",
    "    # Unwrap links [text](url) -> text\n",
    "    s = re.sub(r'\\[([^\\]]+)\\]\\([^\\)]+\\)', r'\\1', s)\n",
    "    # Remove simple formatting markers\n",
    "    s = re.sub(r'[`*_]{1,}', '', s)\n",
    "    # Remove blockquote markers at line start\n",
    "    s = re.sub(r'^\\s*>\\s*', '', s, flags=re.M)\n",
    "    # Normalize spaces\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    return s.strip()\n",
    "\n",
    "def normalize(s: str) -> str:\n",
    "    \"\"\"Normalize Unicode (NFC) and trim surrounding whitespace.\n",
    "\n",
    "    Using NFC ensures that accented characters are stored in a canonical form,\n",
    "    which is important when you later build the charset and train the model.\n",
    "    \"\"\"\n",
    "    return unicodedata.normalize(\"NFC\", s).strip()\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Generate ground truth from Markdown line files.\")\n",
    "    parser.add_argument('--images_dir', required=True, help='Directory containing line images')\n",
    "    parser.add_argument('--md_dir', required=True, help='Directory containing Markdown/text transcriptions')\n",
    "    parser.add_argument('--out', default='gt/ground_truth.txt', help='Output GT file')\n",
    "    parser.add_argument('--images_glob', default='*.*', help=\"Glob pattern for images, default '*.*'\")\n",
    "    parser.add_argument('--join_multiline', action='store_true', default=True,\n",
    "                        help='If set, concatenates all non-empty lines of the .md file')\n",
    "    parser.add_argument('--no-join', dest='join_multiline', action='store_false',\n",
    "                        help='Do not concatenate: use only the first non-empty line')\n",
    "    parser.add_argument('--relpath', action='store_true', default=True,\n",
    "                        help='Write image paths relative to images_dir instead of absolute paths')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    images_dir = Path(args.images_dir)\n",
    "    md_dir = Path(args.md_dir)\n",
    "    outp = Path(args.out)\n",
    "    outp.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Collect all files in images_dir that match the glob pattern\n",
    "    imgs = sorted([p for p in images_dir.glob(args.images_glob) if p.is_file()])\n",
    "    if not imgs:\n",
    "        print(\"Nessuna immagine trovata in\", images_dir, file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    missing_md = []  # track images without a matching transcription\n",
    "    written = 0      # how many GT lines we actually write\n",
    "\n",
    "    with outp.open('w', encoding='utf-8') as fh:\n",
    "        for img in imgs:\n",
    "            stem = img.stem\n",
    "            # Expected Markdown file: same stem + .md\n",
    "            md_path = md_dir / (stem + '.md')\n",
    "            if not md_path.exists():\n",
    "                # Try some alternative text extensions if .md is not present\n",
    "                found = None\n",
    "                for ext in ['.txt', '.mdown', '.markdown']:\n",
    "                    cand = md_dir / (stem + ext)\n",
    "                    if cand.exists():\n",
    "                        found = cand\n",
    "                        break\n",
    "                if found:\n",
    "                    md_path = found\n",
    "                else:\n",
    "                    # No transcription found: record and skip this image\n",
    "                    missing_md.append((img.name, str(md_path)))\n",
    "                    continue\n",
    "\n",
    "            text = md_path.read_text(encoding='utf-8')\n",
    "            # Split into non-empty lines and strip Markdown on each line\n",
    "            lines = [normalize(strip_markdown(l)) for l in text.splitlines() if l.strip()]\n",
    "            if not lines:\n",
    "                # Transcription file exists but has no usable content\n",
    "                missing_md.append((img.name, f\"{md_path} (vuoto)\"))\n",
    "                continue\n",
    "\n",
    "            # Either concatenate all lines or take the first one\n",
    "            if args.join_multiline:\n",
    "                txt = ' '.join(lines)\n",
    "            else:\n",
    "                txt = lines[0]\n",
    "\n",
    "            txt = normalize(strip_markdown(txt))\n",
    "\n",
    "            # Decide how to write the image path in the GT file\n",
    "            if args.relpath:\n",
    "                # Relative to the images_dir, but we store the prefix (e.g. \"00_images/...\")\n",
    "                img_path_str = str(Path(args.images_dir).joinpath(img.name).as_posix())\n",
    "            else:\n",
    "                img_path_str = str(img.resolve())\n",
    "\n",
    "            # Ensure the text has no embedded tabs/newlines, because we use TAB as separator\n",
    "            txt = txt.replace('\\t', ' ').replace('\\r', ' ').replace('\\n', ' ')\n",
    "            fh.write(f\"{img_path_str}\\t{txt}\\n\")\n",
    "            written += 1\n",
    "\n",
    "    print(f\"Wrote {written} lines to {outp}\")\n",
    "    if missing_md:\n",
    "        print(f\"Missing or empty md for {len(missing_md)} images (showing up to 20):\")\n",
    "        for m in missing_md[:20]:\n",
    "            print(\"  -\", m[0], \"expected\", m[1])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Validation and normalization of ground truth\n",
    "\n",
    "After generating `ground_truth_new.txt`, we want to:\n",
    "\n",
    "- check that each line has a path and text separated by a tab;\n",
    "- normalize whitespace and Unicode (NFC) again, in a consistent way;\n",
    "- optionally apply substitutions (e.g. aligning different variants of characters);\n",
    "- detect missing image files and duplicate entries.\n",
    "\n",
    "This step acts as a **sanity check** and produces a cleaned `ground_truth_new_normalized.txt` file that will be used to create train/val/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "bash"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Validate and normalize the newly created ground truth file.\n",
    "#\n",
    "# --gt   : input GT file from the previous step\n",
    "# --root : base directory used to resolve relative image paths\n",
    "# --out  : path to the normalized GT file\n",
    "\n",
    "python3 validate_and_normalize_gt.py \\\n",
    "    --gt \"gt_new/ground_truth_new.txt\" \\\n",
    "    --root \".\" \\\n",
    "    --out \"gt_new/ground_truth_new_normalized.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# validate_and_normalize_gt.py\n",
    "#\n",
    "# PURPOSE\n",
    "# -------\n",
    "# Load an existing ground_truth.txt, check its consistency, normalize\n",
    "# transcriptions, and (optionally) write a cleaned version.\n",
    "#\n",
    "# This helps catch:\n",
    "#   - lines without TAB separator\n",
    "#   - empty transcriptions\n",
    "#   - missing image files\n",
    "#   - duplicate entries for the same image path.\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import unicodedata\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_map(path: str):\n",
    "    \"\"\"Load optional replacement rules from a text file.\n",
    "\n",
    "    The mapping file contains lines of the form:\n",
    "        from<TAB>to\n",
    "    or (as a fallback) two whitespace-separated fields.\n",
    "    This can be used to unify characters or fix common issues.\n",
    "    \"\"\"\n",
    "    m = {}\n",
    "    if not path:\n",
    "        return m\n",
    "    for ln in open(path, encoding='utf-8'):\n",
    "        ln = ln.rstrip('\\n')\n",
    "        if not ln or ln.startswith('#'):\n",
    "            continue\n",
    "        if '\\t' in ln:\n",
    "            a, b = ln.split('\\t', 1)\n",
    "        else:\n",
    "            parts = ln.split(None, 1)\n",
    "            if len(parts) != 2:\n",
    "                continue\n",
    "            a, b = parts\n",
    "        m[a] = b\n",
    "    return m\n",
    "\n",
    "def apply_map(s: str, mapping: dict) -> str:\n",
    "    \"\"\"Apply all substitution rules in `mapping` to the string `s`.\"\"\"\n",
    "    for a, b in mapping.items():\n",
    "        s = s.replace(a, b)\n",
    "    return s\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    \"\"\"Trim, collapse whitespace, and normalize Unicode to NFC.\"\"\"\n",
    "    s = s.strip()\n",
    "    s = ' '.join(s.split())  # collapse multiple spaces\n",
    "    s = unicodedata.normalize('NFC', s)\n",
    "    return s\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Validate and normalize a ground_truth file.\")\n",
    "    parser.add_argument('--gt', required=True, help='Input ground truth file')\n",
    "    parser.add_argument('--root', default='.', help='Root dir to resolve image paths')\n",
    "    parser.add_argument('--out', default=None, help='Output normalized GT file (optional)')\n",
    "    parser.add_argument('--map', default=None, help='Optional substitutions file (from<TAB>to)')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    mapping = load_map(args.map)\n",
    "    root = Path(args.root)\n",
    "    gt = Path(args.gt)\n",
    "    if not gt.exists():\n",
    "        print('gt file not found', gt, file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    missing = []      # lines whose image file does not exist\n",
    "    empty = []        # lines with empty transcription after normalization\n",
    "    bad_lines = []    # lines without TAB separator\n",
    "    duplicates = defaultdict(int)\n",
    "    total = 0\n",
    "    normalized_lines = []\n",
    "\n",
    "    for i, ln in enumerate(gt.read_text(encoding='utf-8').splitlines(), start=1):\n",
    "        if not ln.strip():\n",
    "            continue\n",
    "        if '\\t' not in ln:\n",
    "            bad_lines.append((i, ln))\n",
    "            continue\n",
    "        path, txt = ln.split('\\t', 1)\n",
    "        path = path.strip()\n",
    "        txt = txt.strip()\n",
    "        # Apply substitutions (if any) before final normalization\n",
    "        txt = apply_map(txt, mapping)\n",
    "        txt = normalize_text(txt)\n",
    "        if txt == '':\n",
    "            empty.append((i, path))\n",
    "\n",
    "        # Resolve path relative to root (unless already absolute)\n",
    "        pth = (root / path) if not Path(path).is_absolute() else Path(path)\n",
    "        if not pth.exists():\n",
    "            missing.append((i, path))\n",
    "\n",
    "        duplicates[path] += 1\n",
    "        normalized_lines.append((path, txt))\n",
    "        total += 1\n",
    "\n",
    "    # Console report of what we found\n",
    "    print(f\"Total lines read: {total}\")\n",
    "    if bad_lines:\n",
    "        print(f\"Lines without tab: {len(bad_lines)} (showing up to 10):\")\n",
    "        for i, ln in bad_lines[:10]:\n",
    "            print(i, ln[:200])\n",
    "    if empty:\n",
    "        print(f\"Empty transcriptions: {len(empty)}\")\n",
    "    if missing:\n",
    "        print(f\"Missing image files: {len(missing)} (showing up to 10):\")\n",
    "        for i, pth in missing[:10]:\n",
    "            print(i, pth)\n",
    "    dup_list = [p for p, c in duplicates.items() if c > 1]\n",
    "    if dup_list:\n",
    "        print(f\"Duplicate image entries: {len(dup_list)} (showing up to 10):\")\n",
    "        for pth in dup_list[:10]:\n",
    "            print(pth, duplicates[pth])\n",
    "\n",
    "    # Optionally write the normalized file, ready for splitting\n",
    "    if args.out:\n",
    "        outp = Path(args.out)\n",
    "        outp.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with outp.open('w', encoding='utf-8') as fh:\n",
    "            for path, txt in normalized_lines:\n",
    "                txt_clean = txt.replace('\\t', ' ').replace('\\r', ' ').replace('\\n', ' ')\n",
    "                fh.write(f\"{path}\\t{txt_clean}\\n\")\n",
    "        print(f\"Wrote normalized ground truth to {outp}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating splits and charset\n",
    "\n",
    "Once the normalized ground truth is available, we:\n",
    "\n",
    "- group entries by page (to avoid having lines from the same page in both train and val/test);\n",
    "- split into train/validation/test sets with specified proportions;\n",
    "- extract the set of characters actually used (charset), which Kraken uses to define the output layer.\n",
    "\n",
    "This is done by `split_and_charset.py`. Grouping by page is especially important when the same physical page is split into many line images: we don't want the same handwriting style from the very same page to appear simultaneously in training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "bash"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create train/val/test splits and extract charset from the normalized GT.\n",
    "#\n",
    "# --val  : fraction of examples reserved for validation\n",
    "# --test : fraction for test\n",
    "# --group-by-page : keep lines from the same page together in the same split\n",
    "# --page-sep      : character used in filenames to separate page id from line id\n",
    "\n",
    "python3 split_and_charset.py \\\n",
    "    gt_new/ground_truth_new_normalized.txt \\\n",
    "    --out splits_new \\\n",
    "    --val 0.05 \\\n",
    "    --test 0.05 \\\n",
    "    --group-by-page \\\n",
    "    --page-sep \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# split_and_charset.py\n",
    "#\n",
    "# PURPOSE\n",
    "# -------\n",
    "# Take a normalized ground truth file and:\n",
    "#   - optionally group lines by page\n",
    "#   - split them into train/val/test\n",
    "#   - save the splits as separate files\n",
    "#   - extract the character set used in all transcriptions.\n",
    "\n",
    "import argparse\n",
    "import unicodedata\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    \"\"\"Normalize Unicode (NFC) and trim.\n",
    "\n",
    "    This is applied again in case the GT file still contains some\n",
    "    inconsistencies or extra whitespace.\n",
    "    \"\"\"\n",
    "    return unicodedata.normalize(\"NFC\", s).strip()\n",
    "\n",
    "def read_ground_truth(gt_path: str):\n",
    "    \"\"\"Read a ground truth file and return a list of (image_path, text) pairs.\n",
    "\n",
    "    Each line is expected to be:\n",
    "        <path>\\t<transcription>\n",
    "    Lines without a valid format or with empty text are skipped.\n",
    "    \"\"\"\n",
    "    entries = []\n",
    "    gt_path = Path(gt_path)\n",
    "    if not gt_path.exists():\n",
    "        raise FileNotFoundError(f\"Ground truth file not found: {gt_path}\")\n",
    "    with gt_path.open(\"r\", encoding=\"utf-8\") as fh:\n",
    "        for lineno, line in enumerate(fh, 1):\n",
    "            raw = line.rstrip(\"\\n\")\n",
    "            if not raw.strip():\n",
    "                continue\n",
    "            if \"\\t\" in raw:\n",
    "                img, txt = raw.split(\"\\t\", 1)\n",
    "            else:\n",
    "                # As a fallback, split on first whitespace.\n",
    "                parts = raw.split(None, 1)\n",
    "                if len(parts) != 2:\n",
    "                    print(f\"Warning: salto linea {lineno} (formato non riconosciuto): {raw}\")\n",
    "                    continue\n",
    "                img, txt = parts\n",
    "            txt = normalize_text(txt)\n",
    "            if txt == \"\":\n",
    "                print(f\"Warning: trascrizione vuota a linea {lineno}, salto.\")\n",
    "                continue\n",
    "            entries.append((img, txt))\n",
    "    return entries\n",
    "\n",
    "def group_entries(entries, group_by_page: bool, page_sep: str):\n",
    "    \"\"\"Group entries by page (or return each entry as its own group).\n",
    "\n",
    "    When group_by_page is True, the page id is extracted from the filename\n",
    "    stem using page_sep (e.g. '0001_01.png' -> page '0001'). This ensures all\n",
    "    lines from the same page go to the same split.\n",
    "    \"\"\"\n",
    "    if not group_by_page:\n",
    "        return [[e] for e in entries]\n",
    "    groups = defaultdict(list)\n",
    "    for img, txt in entries:\n",
    "        stem = Path(img).stem\n",
    "        if page_sep and page_sep in stem:\n",
    "            key = stem.split(page_sep, 1)[0]\n",
    "        else:\n",
    "            # Fallback: group by parent directory name\n",
    "            parent = str(Path(img).parent)\n",
    "            key = parent\n",
    "        groups[key].append((img, txt))\n",
    "    return list(groups.values())\n",
    "\n",
    "def split_groups(groups, val_frac: float, test_frac: float, seed: int):\n",
    "    \"\"\"Split groups into train/val/test according to the given fractions.\n",
    "\n",
    "    Groups are shuffled and then greedily assigned to the split that has the\n",
    "    largest remaining deficit. This way we keep all lines from the same page\n",
    "    together, while approximating the desired split ratios.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    random.shuffle(groups)\n",
    "    total = sum(len(g) for g in groups)\n",
    "    n_val = int(total * val_frac + 0.5)\n",
    "    n_test = int(total * test_frac + 0.5)\n",
    "    n_train = total - n_val - n_test\n",
    "\n",
    "    train, val, test = [], [], []\n",
    "    counts = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
    "\n",
    "    for g in groups:\n",
    "        deficits = {\n",
    "            \"train\": n_train - counts[\"train\"],\n",
    "            \"val\": n_val - counts[\"val\"],\n",
    "            \"test\": n_test - counts[\"test\"]\n",
    "        }\n",
    "        # Choose the split with the largest positive deficit; if all are\n",
    "        # non-positive, we fall back to train.\n",
    "        pick = max(deficits.items(), key=lambda x: (x[1], x[0]))[0]\n",
    "        if pick == \"train\":\n",
    "            train.extend(g); counts[\"train\"] += len(g)\n",
    "        elif pick == \"val\":\n",
    "            if counts[\"val\"] + len(g) <= n_val:\n",
    "                val.extend(g); counts[\"val\"] += len(g)\n",
    "            else:\n",
    "                train.extend(g); counts[\"train\"] += len(g)\n",
    "        else:\n",
    "            if counts[\"test\"] + len(g) <= n_test:\n",
    "                test.extend(g); counts[\"test\"] += len(g)\n",
    "            else:\n",
    "                train.extend(g); counts[\"train\"] += len(g)\n",
    "    return train, val, test\n",
    "\n",
    "def write_split(out_dir: str, name: str, entries):\n",
    "    \"\"\"Write a split file `<name>.txt` containing `path<TAB>text` per line.\"\"\"\n",
    "    out = Path(out_dir)\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "    path = out / f\"{name}.txt\"\n",
    "    with path.open(\"w\", encoding=\"utf-8\") as fh:\n",
    "        for img, txt in entries:\n",
    "            fh.write(f\"{img}\\t{txt}\\n\")\n",
    "    print(f\"Wrote {len(entries)} lines to {path}\")\n",
    "\n",
    "def extract_charset(entries, out_dir: str):\n",
    "    \"\"\"Extract the set of characters used in all transcriptions.\n",
    "\n",
    "    This is useful for inspecting the data and for configuring the OCR model's\n",
    "    output layer (alphabet).\n",
    "    \"\"\"\n",
    "    chars = set()\n",
    "    for _, txt in entries:\n",
    "        chars.update(txt)\n",
    "    chars.discard(\"\\n\"); chars.discard(\"\\r\")\n",
    "    chars = sorted(chars)\n",
    "    out = Path(out_dir); out.mkdir(parents=True, exist_ok=True)\n",
    "    charset_path = out / \"charset.txt\"\n",
    "    with charset_path.open(\"w\", encoding=\"utf-8\") as fh:\n",
    "        for c in chars:\n",
    "            fh.write(c + \"\\n\")\n",
    "    # Also provide a single-line version for quick inspection\n",
    "    with (out / \"charset_one_line.txt\").open(\"w\", encoding=\"utf-8\") as fh:\n",
    "        fh.write(\"\".join(chars))\n",
    "    print(f\"Extracted {len(chars)} unique characters -> {charset_path}\")\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Genera splits e charset da ground_truth\")\n",
    "    parser.add_argument(\"gt\", help=\"Percorso al file ground_truth (path<TAB>trascrizione per riga)\")\n",
    "    parser.add_argument(\"--out\", \"-o\", default=\"splits\", help=\"Cartella di output\")\n",
    "    parser.add_argument(\"--val\", type=float, default=0.05, help=\"Frazione per validation (default 0.05)\")\n",
    "    parser.add_argument(\"--test\", type=float, default=0.05, help=\"Frazione per test (default 0.05)\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=42, help=\"Seed per random shuffle\")\n",
    "    parser.add_argument(\"--group-by-page\", action=\"store_true\",\n",
    "                        help=\"Evitare contaminazione raggruppando righe della stessa pagina\")\n",
    "    parser.add_argument(\"--page-sep\", default=\"_\",\n",
    "                        help=\"Separatore per estrarre ID pagina dal file stem\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    entries = read_ground_truth(args.gt)\n",
    "    if not entries:\n",
    "        print(\"Nessuna entry trovata nel ground truth. Esco.\")\n",
    "        return\n",
    "    print(f\"Letti {len(entries)} righe dal ground truth.\")\n",
    "    groups = group_entries(entries, args.group_by_page, args.page_sep)\n",
    "    print(f\"Raggruppati in {len(groups)} gruppi (group_by_page={args.group_by_page}).\")\n",
    "    train, val, test = split_groups(groups, args.val, args.test, args.seed)\n",
    "    write_split(args.out, \"train\", train)\n",
    "    write_split(args.out, \"val\", val)\n",
    "    write_split(args.out, \"test\", test)\n",
    "    write_split(args.out, \"ground_truth_all\", train + val + test)\n",
    "    extract_charset(entries, args.out)\n",
    "    print(\"Fatto.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick sanity check on the generated splits: we check how many lines each split contains and we print the first few lines of `train.txt` to visually verify the format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "bash"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Check number of lines in each split and show first few entries from train.\n",
    "# This is useful to quickly see if the splits look reasonable.\n",
    "wc -l splits_new/*.txt || true\n",
    "echo\n",
    "sed -n '1,5p' splits_new/train.txt || true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image preprocessing pipeline\n",
    "\n",
    "Ketos expects line images in a **consistent format** (same height, good contrast, minimal skew). We use ImageMagick (`convert`) to:\n",
    "\n",
    "- deskew lines (`-deskew 40%`),\n",
    "- convert to grayscale (`-colorspace Gray`),\n",
    "- resize to a fixed height (64 px here, `-resize x64`),\n",
    "- center the line in a fixed canvas (`-extent 0x64`).\n",
    "\n",
    "The shell snippet below processes all line images and writes them into `processed/lines/`. This step reduces unwanted variability in the input that might make training harder or slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "bash"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Preprocess line images for ketos (deskew, grayscale, resize, center).\n",
    "#\n",
    "# This loop:\n",
    "#   - creates processed/lines if needed\n",
    "#   - iterates over each .png image in 00_images\n",
    "#   - applies a sequence of ImageMagick operations\n",
    "\n",
    "mkdir -p processed/lines\n",
    "\n",
    "for f in 00_images/*.png; do\n",
    "    base=$(basename \"$f\")\n",
    "    convert \"$f\" \\\n",
    "        -deskew 40% \\\n",
    "        -colorspace Gray \\\n",
    "        -resize x64 \\\n",
    "        -background white -gravity center -extent 0x64 \\\n",
    "        \"processed/lines/$base\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing, the paths in the split files still point to `00_images/...`. We need to update them so that they refer to the preprocessed images in `processed/lines/`.\n",
    "\n",
    "This is a **pure string replacement** in the split files and does not change the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "bash"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Update image paths in split files to use processed/lines instead of 00_images.\n",
    "# The text part after the TAB remains unchanged.\n",
    "\n",
    "sed 's|^00_images/|processed/lines/|' splits_new/train.txt > splits_new/train_proc.txt\n",
    "sed 's|^00_images/|processed/lines/|' splits_new/val.txt   > splits_new/val_proc.txt\n",
    "sed 's|^00_images/|processed/lines/|' splits_new/test.txt  > splits_new/test_proc.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extracting image lists and creating sidecar files\n",
    "\n",
    "Kraken/ketos training can work with:\n",
    "- a split file containing `image\\ttext`, **or**\n",
    "- a list of image paths plus separate `.gt.txt` files (sidecars) containing the transcription.\n",
    "\n",
    "In this workflow we create:\n",
    "- `train_images.txt`, `val_images.txt`, `test_images.txt` – one image path per line;\n",
    "- `*.gt.txt` sidecars in the same directory as the images, each containing the corresponding transcription.\n",
    "\n",
    "This layout is convenient when you want to reuse the same splits with different Kraken commands or configurations without rewriting a big GT file each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "bash"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Extract only image paths from the processed splits (train/val/test).\n",
    "# We drop the text part and keep only the first TAB-separated field.\n",
    "\n",
    "awk -F'\\t' '{print $1}' splits_new/train_proc.txt > splits_new/train_images.txt\n",
    "awk -F'\\t' '{print $1}' splits_new/val_proc.txt   > splits_new/val_images.txt\n",
    "awk -F'\\t' '{print $1}' splits_new/test_proc.txt  > splits_new/test_images.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Inline script to create sidecar .gt.txt files from split files.\n",
    "#\n",
    "# PURPOSE\n",
    "# -------\n",
    "# For each line in train_proc/val_proc/test_proc:\n",
    "#     <image_path>\\t<text>\n",
    "# we create a file <image_path>.gt.txt that contains <text>.\n",
    "#\n",
    "# This is the format that recent versions of ketos expect when we pass only\n",
    "# lists of images for training/validation.\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def write_sidecars(split_path: str) -> int:\n",
    "    \"\"\"Create .gt.txt sidecar files for each image in a split.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    split_path : str\n",
    "        Path to a file where each line is `image_path<TAB>text`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Number of sidecar files created.\n",
    "    \"\"\"\n",
    "    p = Path(split_path)\n",
    "    created = 0\n",
    "    with p.open(encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f, 1):\n",
    "            line = line.rstrip('\\n')\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            try:\n",
    "                img, txt = line.split('\\t', 1)\n",
    "            except ValueError:\n",
    "                # If a line does not contain a TAB, we warn and skip it.\n",
    "                print(f\"[WARN] line {i} without TAB in {split_path}: {line[:120]}...\")\n",
    "                continue\n",
    "\n",
    "            img_path = Path(img)\n",
    "            if not img_path.exists():\n",
    "                # It is important that every image mentioned in the split actually exists.\n",
    "                print(f\"[WARN] missing image at line {i}: {img_path}\")\n",
    "                continue\n",
    "\n",
    "            # Sidecar filename: image_name.gt.txt next to the image.\n",
    "            sidecar = img_path.with_suffix('.gt.txt')  # e.g. foo.png -> foo.gt.txt\n",
    "            text = txt.strip('\\r\\n')\n",
    "            sidecar.write_text(text + '\\n', encoding='utf-8')\n",
    "            created += 1\n",
    "    return created\n",
    "\n",
    "total = 0\n",
    "for sp in ['splits_new/train_proc.txt', 'splits_new/val_proc.txt', 'splits_new/test_proc.txt']:\n",
    "    if Path(sp).exists():\n",
    "        c = write_sidecars(sp)\n",
    "        print(f\"[OK] {sp}: created {c} sidecar files\")\n",
    "        total += c\n",
    "print(\"Total new sidecars created:\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Verification: check that each image in the image lists has a corresponding .gt.txt sidecar.\n",
    "#\n",
    "# This is a defensive check: it tells us if some images that we plan to use\n",
    "# for training are missing their transcription file.\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "missing = []\n",
    "for lst in ['splits_new/train_images.txt', 'splits_new/val_images.txt', 'splits_new/test_images.txt']:\n",
    "    p = Path(lst)\n",
    "    if not p.exists():\n",
    "        continue\n",
    "    for l in p.read_text(encoding='utf-8').splitlines():\n",
    "        img = Path(l.strip())\n",
    "        if not img.exists():\n",
    "            # If the image itself is missing, the dataset is inconsistent;\n",
    "            # we skip here but this should be investigated.\n",
    "            continue\n",
    "        gt = img.with_suffix('.gt.txt')\n",
    "        if not gt.exists():\n",
    "            missing.append(str(img))\n",
    "\n",
    "print(\"Total images without sidecar:\", len(missing))\n",
    "if missing[:10]:\n",
    "    print(\"First missing:\", missing[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training the Kraken model with ketos\n",
    "\n",
    "Finally, we launch training using `ketos train`, starting from the pre‑trained Latin manuscript model `Tridis_Medieval_EarlyModern.mlmodel` and fine‑tuning it on our Italian dataset.\n",
    "\n",
    "### Why these hyperparameters?\n",
    "\n",
    "- `-i models/Tridis_Medieval_EarlyModern.mlmodel`: we reuse a model trained on medieval/early modern Latin manuscripts, which are graphically similar to the Italian handwriting in our data.\n",
    "- `--resize union`: combine training images into a common height while preserving aspect ratio in a way compatible with the model.\n",
    "- `-N 40`: maximum number of epochs.\n",
    "- `--min-epochs 5`: ensure at least a few passes over the data before early stopping.\n",
    "- `--lag 10`: patience for early stopping (number of epochs without improvement on validation before stopping).\n",
    "- `-B 4`: batch size; relatively small here due to GPU memory and image size.\n",
    "- `-r 5e-5`: learning rate; small step size for fine‑tuning to avoid destroying what the base model has already learned.\n",
    "- `-t`/`-e`: text files listing images for training and validation.\n",
    "\n",
    "> **Note:** This command is intended to be run in a shell inside the conda environment where Kraken/ketos are installed. Adjust paths and hyperparameters as needed for your setup and your GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "bash"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Fine-tune Kraken model with ketos.\n",
    "#\n",
    "# IMPORTANT:\n",
    "# - Run this in a terminal within the environment where kraken/ketos is installed.\n",
    "# - Make sure the base model path (-i) and output paths (-o) exist or can be created.\n",
    "# - Ensure that splits_new/train_images.txt and splits_new/val_images.txt point\n",
    "#   to images that have matching .gt.txt sidecars.\n",
    "\n",
    "ketos train \\\n",
    "    -f path \\\n",
    "    -i \"models/Tridis_Medieval_EarlyModern.mlmodel\" \\\n",
    "    --resize union \\\n",
    "    -q early \\\n",
    "    -N 40 \\\n",
    "    --min-epochs 5 \\\n",
    "    --lag 10 \\\n",
    "    -B 4 \\\n",
    "    -r 5e-5 \\\n",
    "    -o models/italian_finetuned.mlmodel_best.mlmodel \\\n",
    "    -t splits_new/train_images.txt \\\n",
    "    -e splits_new/val_images.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "This notebook mirrors and expands the code part of the LaTeX report and provides a structured, executable view of the complete pipeline used to:\n",
    "\n",
    "- prepare line images and Markdown transcriptions for Kraken,\n",
    "- validate and normalize the ground truth file,\n",
    "- create robust train/validation/test splits and extract the charset,\n",
    "- preprocess line images with ImageMagick,\n",
    "- generate sidecar `.gt.txt` files,\n",
    "- and train a fine‑tuned OCR model for Italian handwritten manuscripts based on Kraken.\n",
    "\n",
    "The additional comments aim to clarify:\n",
    "\n",
    "- the purpose of each script and command,\n",
    "- the reasons behind design choices (e.g. grouping by page, Unicode normalization, reuse of a Latin base model),\n",
    "- and potential points where you may need to adapt paths or parameters for your own environment.\n",
    "\n",
    "You can now use this notebook both as a **didactic explanation** of the pipeline and as a **starting point** to run further experiments or extend the project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}