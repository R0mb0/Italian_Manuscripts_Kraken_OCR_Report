\documentclass[11pt,a4paper]{article}

% Lingua e codifica
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage[T1]{fontenc}

% Matematica e simboli
\usepackage{amsmath,amssymb}

% Grafica e colori
\usepackage[pdftex]{graphicx}
\usepackage[svgnames]{xcolor}

% Layout e paragrafi
\usepackage[margin=1in]{geometry}
\usepackage{parskip}
\usepackage{enumitem}

% Tabelle
\usepackage{array}
\usepackage{booktabs}

% Link ipertestuali
\usepackage{hyperref}

% Codice
\usepackage{minted}
\setminted{
	frame=single,
	linenos,
	fontsize=\footnotesize,
	breaklines,
	breakanywhere,
	numbersep=4pt,
	xleftmargin=6pt,
	framesep=2pt
}

% Grafici
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

% Bibliografia
\usepackage{csquotes}
\usepackage{biblatex}
\addbibresource{riferimenti.bib}

% Intestazione
\title{\textbf{Applicazione di Reti Neurali Ricorrenti e Convoluzionali per la Digitalizzazione di Archivi Storici}}
\author{Francesco Rombaldoni\\
	\small Corso di \textbf{Applicazioni dell'Intelligenza Artificiale}\\
	\small Universit\`a degli Studi di Urbino Carlo Bo\\
	\small \texttt{f.rombaldoni@campus.uniurb.it}}
\date{\today}

\begin{document}
	
	\maketitle
	
	\begin{abstract}
		\noindent Il presente elaborato descrive la progettazione e l'implementazione di un sistema di \emph{Handwritten Text Recognition} (HTR) basato su Deep Learning, sviluppato per le esigenze archivistiche dell'INRCA (Istituto Nazionale di Riposo e Cura per Anziani). Il progetto affronta la sfida della dematerializzazione di documenti sanitari storici, vincolata da stringenti normative sulla privacy (GDPR) che impediscono l'uso di servizi cloud commerciali. Viene presentata una pipeline completa che utilizza il framework open-source \textbf{Kraken}: dalla pre-elaborazione delle immagini (binarizzazione, deskewing) all'addestramento di un modello ibrido CNN-LSTM. Particolare attenzione è dedicata all'analisi dell'architettura neurale, che combina reti convoluzionali per l'estrazione di feature visive e reti ricorrenti per la modellazione sequenziale del testo, evidenziando come queste tecnologie risolvano le criticità legate alla variabilità della grafia manoscritta in ambito medico.
	\end{abstract}
	
	%\tableofcontents
	\newpage
	
	\section{Introduzione e Contesto Operativo}
	
	L'applicazione delle tecnologie di Intelligenza Artificiale in ambito sanitario non riguarda esclusivamente la diagnostica o la genomica, ma gioca un ruolo cruciale anche nella gestione del patrimonio informativo (Information Retrieval e Data Mining).
	Questo progetto nasce all'interno dell'INRCA, un Istituto di Ricovero e Cura a Carattere Scientifico (IRCCS) pubblico, che si trova a dover gestire vasti archivi cartacei storici contenenti dati sensibili dei pazienti.
	
	\subsection{Il Problema: Normativa e Conservazione}
	La gestione di tali archivi è soggetta a dei \textbf{Vincoli Normativi (GDPR)} come il Regolamento UE 2016/679 che impone rigorosi limiti alla conservazione dei dati personali ("diritto all'oblio") e standard di sicurezza elevati. Spesso, la normativa impone la distruzione del supporto fisico dopo un certo periodo (es. 10, 20 o 40 anni), rischiando di perdere per sempre l'informazione se non adeguatamente digitalizzata.\newline
	L'obiettivo è quindi creare una "copia digitale fedele" e ricercabile che permetta di distruggere il cartaceo mantenendo l'informazione, in conformità agli standard ISO/IEC 21964.
	
	\subsection{Analisi delle Soluzioni Esistenti e Scelta Tecnologica}
	Inizialmente sono state valutate soluzioni commerciali (OCR tradizionali come ABBYY o servizi Cloud come Google Vision API). Queste sono state scartate per due motivi principali:
	\begin{enumerate}
		\item \textbf{Privacy e Sovranità dei Dati:} L'invio di scansioni contenenti dati sanitari verso server cloud di terze parti (spesso extra-UE) presenta criticità insormontabili per un ente pubblico. È necessario un sistema \emph{on-premise} (locale).
		\item \textbf{Limiti degli OCR tradizionali:} I motori OCR classici funzionano bene su testo stampato, ma falliscono sul manoscritto corsivo (\emph{Handwritten Text Recognition} - HTR), dove la segmentazione dei singoli caratteri è ambigua.
	\end{enumerate}
	
	La scelta è ricaduta su \textbf{Kraken}, un motore HTR open-source basato su reti neurali, che permette l'addestramento fine-grained su specifiche calligrafie e l'esecuzione interamente locale.
	
	\section{Fondamenti Teorici dell'Architettura}
	
	Il cuore del sistema Kraken si basa su un'architettura ibrida che rispecchia i modelli di Deep Learning analizzati durante il corso: l'integrazione di Reti Convoluzionali (CNN) e Reti Ricorrenti (RNN).
	
	\subsection{Dall'Immagine alla Sequenza: CNN e Feature Extraction}
	Le \textbf{CNN (Convolutional Neural Networks)} sono eccellenti nell'estrarre caratteristiche spaziali locali.\newline
	Nel contesto dell'HTR, l'input non è l'intera pagina, ma una singola riga di testo normalizzata in altezza. La CNN scorre lungo questa "striscia" di pixel applicando filtri (kernel) che rilevano pattern primitivi: tratti verticali, curve, occhielli.
	L'output della CNN non è una classificazione ("questo è un gatto"), ma una sequenza di vettori di feature (\emph{feature maps}) che rappresentano la morfologia del testo lungo l'asse orizzontale.
	
	\subsection{Modellazione del Contesto: RNN e LSTM}
	La scrittura è intrinsecamente sequenziale: la forma di una lettera è influenzata da quelle adiacenti (legature del corsivo) e l'interpretazione di un segno ambiguo dipende dal contesto della parola.
	Per questo, le feature estratte dalla CNN vengono passate a una **RNN (Recurrent Neural Network)**. Nello specifico, si utilizzano celle **LSTM (Long Short-Term Memory)** Bidirezionali (BLSTM).
	\begin{itemize}
		\item \textbf{Memoria a Lungo Termine:} Le LSTM risolvono il problema della "scomparsa del gradiente" (\emph{vanishing gradient}) tipico delle RNN semplici, permettendo alla rete di ricordare il contesto anche a distanza di molti caratteri.
		\item \textbf{Bidirezionalità:} La rete legge la riga sia da sinistra a destra che viceversa, utilizzando il contesto futuro e passato per disambiguare il carattere corrente.
	\end{itemize}
	
	\subsection{Allineamento e Loss Function (CTC)}
	Un problema classico nel riconoscimento del manoscritto è che non sappiamo "dove" inizia e finisce esattamente un carattere nell'immagine. Per evitare la costosa operazione di segmentare manualmente ogni lettera, si utilizza la **Connectionist Temporal Classification (CTC)**.
	La CTC permette di addestrare la rete fornendo solo l'immagine della riga e la stringa di testo corrispondente. La funzione di loss calcola la probabilità di tutti i possibili allineamenti tra la sequenza di output della rete e il testo target, massimizzando la probabilità della trascrizione corretta.
	
	\section{Metodologia Sperimentale}
	
	Il progetto ha seguito una pipeline rigorosa di preparazione dei dati e addestramento, fondamentale per ottenere risultati validi in sistemi di Machine Learning supervisionati.
	
	\subsection{Acquisizione e Pre-processing (Data Cleaning)}
	La qualità del dataset è determinante. Sono state selezionate 150 pagine di documenti rappresentativi.
	La fase di pre-processing ha utilizzato il tool \emph{ScanTailor} per operazioni di pulizia essenziali:
	\begin{enumerate}
		\item \textbf{Deskewing:} Correzione dell'inclinazione della pagina per garantire righe orizzontali.
		\item \textbf{Binarizzazione:} Conversione dell'immagine in bianco e nero puro. Questo passaggio rimuove il rumore di fondo (ingiallimento della carta, macchie) e isola l'inchiostro, facilitando il lavoro della CNN.
		\item \textbf{Segmentazione Layout:} Definizione dell'area utile contenente il testo, scartando bordi e note marginali irrilevanti.
	\end{enumerate}
	
	\subsection{Annotazione e Creazione del Ground Truth}
	Per l'addestramento supervisionato è necessario un \emph{Ground Truth} (GT) affidabile. Le immagini processate sono state caricate in un ambiente di annotazione dove è stata effettuata:
	\begin{itemize}
		\item \textbf{Segmentazione delle righe:} Un algoritmo basato su proiezioni orizzontali ha individuato le righe di testo (baselines).
		\item \textbf{Trascrizione Manuale:} Ogni riga è stata trascritta manualmente. Questa fase è stata critica per definire le convenzioni di trascrizione (es. come trattare le correzioni, le abbreviazioni mediche, la punteggiatura).
	\end{itemize}
	Il risultato è un dataset di coppie (immagine riga, testo UTF-8).
	
	\subsection{Strategia di Training: Fine-Tuning}
	Considerata la dimensione ridotta del dataset (150 pagine), l'addestramento di una rete profonda da zero (\emph{from scratch}) avrebbe portato quasi certamente all'\textbf{overfitting} (la rete impara a memoria i dati di training ma non generalizza su nuovi dati).
	Si è quindi adottata una tecnica di \textbf{Transfer Learning}:
	\begin{itemize}
		\item Si è partiti da un modello Kraken pre-addestrato su un ampio corpus generico.
		\item Si è effettuato il \emph{fine-tuning} (raffinamento dei pesi) utilizzando il dataset specifico dell'INRCA.
	\end{itemize}
	Questo approccio ha permesso alla rete di sfruttare la conoscenza pregressa su come riconoscere forme base di caratteri, adattandosi poi allo stile calligrafico specifico e al lessico medico dei documenti target.
	
	\section{Risultati e Discussione}
	
	Il modello è stato valutato sia sul set di addestramento sia su un set di validazione separato, non utilizzato durante la fase di training, per stimarne le reali capacità in produzione.
	
	\section{Risultati sperimentali}
	
	\subsection{Metrica utilizzata}
	
	Dato che il modello opera riga per riga producendo sequenze di caratteri, la valutazione naturale
	sarebbe basata su indicatori quali il \emph{Character Error Rate} (CER) o il \emph{Word Error
		Rate} (WER). Nel presente progetto, tuttavia, la metrica pi\`u rilevante per l'utente finale
	(l'operatore che utilizza le trascrizioni per la ricerca documentale e per adempiere agli obblighi
	normativi) \`e la correttezza delle singole parole.
	
	Per questo motivo si considera la seguente metrica intuitiva:
	
	{
		\footnotesize
		\[
		\text{Accuratezza parole} =
		\frac{\text{\# parole riconosciute correttamente}}{\text{\# parole totali}}.
		\]
	}
	
	In tutti gli esperimenti ogni prova consiste nel sottoporre al modello un foglio contenente
	100 parole manoscritte, e nel contare quante di esse vengono riconosciute correttamente. I
	risultati riportati sono calcolati su 20 prove indipendenti per ciascuno scenario e vengono
	sintetizzati tramite media e deviazione standard.
	
	\subsection{Scenario 1: stessa calligrafia del training}
	
	Nel primo scenario il modello \`e stato testato su pagine appartenenti agli stessi documenti
	utilizzati per il training, quindi:
	\begin{itemize}[noitemsep]
		\item stessa persona che ha scritto a mano tutte le pagine;
		\item stessa tipologia di carta e impaginazione;
		\item condizioni di scansione controllate (600 dpi e pre‑elaborazione con ScanTailor).
	\end{itemize}
	
	Sono state condotte 20 prove indipendenti. In ciascuna prova il modello ha riconosciuto un foglio
	contenente 100 parole, e per ogni foglio \`e stato contato il numero di parole trascritte
	correttamente. La media sulle 20 prove risulta pari a:
	\[
	\text{Accuratezza media} \approx 88\% \pm 2\%,
	\]
	dove $\pm 2\%$ rappresenta approssimativamente la deviazione standard tra le prove (ossia,
	nella maggior parte dei casi, l'accuratezza per singolo foglio ricade nell'intervallo 86–90\%).
	
	Gli errori non comportano quasi mai uno stravolgimento completo della parola, ma consistono
	piuttosto in sostituzioni di singole lettere graficamente simili (ad esempio \emph{``casa''}
	riconosciuta come \emph{``caso''}). Questi risultati indicano che il \emph{fine tuning} ha
	effettivamente permesso al modello di apprendere in maniera soddisfacente la calligrafia
	specifica dell'autore dei documenti.
	
	\subsection{Scenario 2: calligrafia diversa}
	
	Nel secondo scenario l'OCR \`e stato applicato a pagine manoscritte da una persona diversa, ma
	su fogli con caratteristiche simili (righe prestampate, impaginazione analoga a quella dei
	documenti usati in addestramento).
	
	Anche in questo caso sono state condotte 20 prove indipendenti, ciascuna su un foglio contenente
	100 parole. La media sulle 20 prove risulta pari a:
	\[
	\text{Accuratezza media} \approx 61\% \pm 2\%,
	\]
	cio\`e il modello riconosce correttamente in media 61 parole su 100, con una variabilit\`a tra le
	prove di circa due punti percentuali.
	
	L'output rimane comunque leggibile e utile come bozza iniziale, ma la quantit\`a di correzioni
	manuali richieste aumenta sensibilmente. Questa diminuzione di prestazioni mette in luce un
	aspetto atteso: con un dataset di addestramento relativamente limitato (circa 150 pagine), il
	modello tende a specializzarsi sulla calligrafia di riferimento e fatica a generalizzare a
	scritture diverse, pur mantenendo una certa capacit\`a di riconoscere la struttura delle parole.
	
	\subsection{Ruolo della qualit\`a di scansione}
	
	Durante i test \`e emerso che una parte consistente delle difficolt\`a non \`e dovuta soltanto
	alla calligrafia, ma anche alla qualit\`a della scansione. Pagine acquisite con inclinazione
	eccessiva, contrasto basso o sfocatura locale risultano notevolmente pi\`u difficili da
	riconoscere, indipendentemente dal contenuto testuale.
	
	Ci\`o suggerisce che, oltre al miglioramento del modello, un elemento cruciale per aumentare
	l'accuratezza complessiva \`e il controllo del processo di acquisizione (scelta dello scanner,
	impostazioni stabili, eventuale normalizzazione delle immagini prima del riconoscimento).
	
	\subsection{Sintesi dei risultati}
	
	La Tabella~\ref{tab:accuracy_scenari} riassume i risultati principali:
	
	\begin{table}[h]
		\centering
		\begin{tabular}{@{}l c@{}}
			\toprule
			Scenario di test & Accuratezza parole (media \(\pm\) dev. std.) \\
			\midrule
			Stessa persona (documenti di riferimento) & \(88\% \pm 2\%\) \\
			Altra persona, stessa tipologia di fogli  & \(61\% \pm 2\%\) \\
			\bottomrule
		\end{tabular}
		\caption{Accuratezza a livello di parola in due scenari di test, calcolata su 20 prove indipendenti per scenario (100 parole per prova).}
		\label{tab:accuracy_scenari}
	\end{table}
	
	\begin{figure}[h]
		\centering
		\begin{tikzpicture}
			\begin{axis}[
				ybar,
				ymin=0,ymax=100,
				bar width=18pt,
				enlarge x limits=0.35,
				ylabel={Accuratezza parole (\%)},
				symbolic x coords={Stessa persona,Altra persona},
				xtick=data,
				nodes near coords,
				nodes near coords align={vertical},
				width=0.9\columnwidth,
				height=0.55\textheight,
				ylabel style={font=\small},
				tick label style={font=\small},
				]
				\addplot coordinates {
					(Stessa persona, 88)
					(Altra persona, 61)
				};
			\end{axis}
		\end{tikzpicture}
		\caption{Accuratezza media a livello di parola nei due scenari di test considerati (20 prove da 100 parole ciascuna per scenario).}
		\label{fig:accuracy_bar}
	\end{figure}
	
	\begin{figure}[h]
		\centering
		\begin{tikzpicture}
			\begin{axis}[
				xlabel={Numero di pagine annotate per il training},
				ylabel={Accuratezza parole (\%)},
				xmin=0, xmax=1050,
				ymin=60, ymax=100,
				xtick={0,50,100,150,300,1000},
				ytick={60,70,80,90,100},
				width=0.9\columnwidth,
				height=0.55\textheight,
				grid=both,
				grid style={gray!20},
				tick label style={font=\small},
				xlabel style={font=\small},
				ylabel style={font=\small},
				]
				\addplot[
				color=FireBrick,
				mark=*,
				thick
				] coordinates {
					(50, 75)
					(100, 83)
					(150, 88)
					(300, 92)
					(1000, 95)
				};
			\end{axis}
		\end{tikzpicture}
		\caption{Andamento qualitativo atteso dell'accuratezza a livello di parola al crescere del numero di pagine annotate utilizzate per il training. Il punto a 150 pagine corrisponde ai risultati effettivamente ottenuti; gli altri valori sono stime indicative.}
		\label{fig:accuracy_vs_pages}
	\end{figure}
	
	\section{Conclusioni}
	
	I risultati ottenuti indicano che il modello fine‑tuned rappresenta una prima base operativa per
	l'introduzione di un OCR per manoscritti italiani all'interno dell'INRCA. Nel caso della
	calligrafia specifica utilizzata per l'addestramento, il sistema raggiunge un'accuratezza a
	livello di parola prossima al 90\%, consentendo di ridurre in modo sensibile il tempo necessario
	per produrre trascrizioni utilizzabili.
	
	\section{Conclusioni e Sviluppi Futuri}
	
	Il progetto ha dimostrato che è possibile applicare tecniche avanzate di Deep Learning (CNN+LSTM) per risolvere problemi concreti di gestione documentale in ambito sanitario, rispettando i vincoli di privacy imposti dal GDPR tramite elaborazione locale.
	
	Per elevare il sistema a un livello di affidabilità sufficiente per essere impiegato, sono state identificate le seguenti linee di sviluppo:
	\begin{itemize}
		\item aumentare significativamente il numero di pagine annotate, passando dalle circa 150 attuali ad almeno un ordine di grandezza superiore (nell'ordine delle mille pagine), in modo da migliorare la capacit\`a di generalizzazione del modello;
		\item coinvolgere il DPO aziendale per definire un protocollo di selezione, anonimizzazione e utilizzo di un campione rappresentativo di documenti clinici reali;
		\item rafforzare la pipeline di acquisizione delle immagini, standardizzando il processo di scansione e le operazioni di pre‑elaborazione;
		\item valutare l'introduzione di un modulo di post‑processing linguistico (ad esempio un correttore contestuale) che possa correggere automaticamente gli errori pi\`u frequenti sulla base del lessico e del contesto.
	\end{itemize}
	
	In prospettiva, il lavoro svolto costituisce un primo tassello concreto verso la realizzazione di
	uno strumento OCR conforme sia alle esigenze operative sia agli obblighi normativi in materia di
	protezione dei dati e conservazione della documentazione storica.
	
	\printbibliography
	
\end{document}