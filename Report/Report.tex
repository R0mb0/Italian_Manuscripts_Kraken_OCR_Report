\documentclass[11pt,a4paper]{article}

% Lingua e codifica
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage[T1]{fontenc}

% Matematica e simboli
\usepackage{amsmath,amssymb}

% Grafica e colori
\usepackage[pdftex]{graphicx}
\usepackage[svgnames]{xcolor}

% Layout e paragrafi
\usepackage[margin=1in]{geometry}
\usepackage{parskip}
\usepackage{enumitem}

% Tabelle
\usepackage{array}
\usepackage{booktabs}

% Link ipertestuali
\usepackage{hyperref}

% Codice
\usepackage{minted}
\setminted{
  frame=single,
  linenos,
  fontsize=\footnotesize,
  breaklines,
  breakanywhere,
  numbersep=4pt,
  xleftmargin=6pt,
  framesep=2pt
}

% Grafici
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

% Bibliografia
\usepackage{csquotes}
\usepackage{biblatex}
\addbibresource{riferimenti.bib}

% Titolo e autori
\title{Realizzazione di un sistema OCR per manoscritti italiani mediante Kraken}
\author{Francesco Rombaldoni\\
\small Applicazioni dell'Intelligenza Artificiale\\
\small Universit\`a degli Studi di Urbino Carlo Bo\\
\small \texttt{f.rombaldoni@campus.uniurb.it}}
\date{}

\begin{document}
\maketitle

\begin{abstract}
Il lavoro descritto in questo articolo riguarda il \emph{fine tuning} di un modello pre‑esistente di Kraken, con l'obiettivo di ottenere un sistema in grado di leggere manoscritti in lingua italiana. Nel contesto della pubblica amministrazione esiste una forte necessit\`a di strumenti OCR avanzati per la digitalizzazione di documenti storici che, a causa delle normative sulla privacy, dovranno essere distrutti dopo la scadenza dei tempi di conservazione.

Per raggiungere questo obiettivo sono stati selezionati documenti manoscritti di cui si possedevano gi\`a le trascrizioni. Le pagine sono state scannerizzate, pre‑elaborate con strumenti standard (in particolare ScanTailor) e quindi utilizzate per generare il \emph{ground truth} necessario all'addestramento. I dati cos\`i ottenuti sono stati organizzati e normalizzati mediante una serie di script in Python, sviluppati appositamente per l'utilizzo con Kraken.

Il risultato di questo processo \`e un modello specializzato per la calligrafia italiana adottata nei documenti di riferimento, che raggiunge un'accuratezza media di circa l'88\% a livello di parola su pagine simili a quelle di addestramento (con una deviazione standard di circa 2 punti percentuali). Sebbene il modello non sia ancora sufficientemente affidabile per un utilizzo completamente automatico sulla documentazione clinica, esso costituisce una prova di concetto concreta e gi\`a utile per motivare la richiesta di risorse aggiuntive, in vista dello sviluppo di uno strumento OCR conforme alle esigenze normative e organizzative dell'INRCA.
\end{abstract}

\section{Introduzione}

\subsection{Contesto applicativo}

Il problema affrontato in questo lavoro nasce dall'esigenza di adeguare la gestione documentale dell'INRCA alle normative vigenti in materia di protezione dei dati personali e conservazione dei documenti, in particolare il Regolamento (UE) 2016/679 (GDPR) e la norma ISO/IEC 21964, che disciplina la transizione dal supporto cartaceo al digitale.

L'INRCA, in quanto istituto sia ospedaliero sia di ricerca, \`e tenuto a garantire il rispetto di tali obblighi, in particolare per quanto riguarda la catalogazione, l'archiviazione e la successiva distruzione dei documenti sensibili. Ci\`o rende necessario disporre di strumenti OCR affidabili, in grado di supportare la digitalizzazione massiva di documenti storici, spesso contenenti anche parti manoscritte.

Una prima analisi ha preso in considerazione alcuni software commerciali largamente diffusi:
\begin{itemize}[noitemsep]
  \item Wondershare PDFelement;
  \item ABBYY FineReader PDF 16;
  \item Nanonets;
  \item Adobe Acrobat.
\end{itemize}

Tali strumenti sono stati tuttavia scartati in quanto inadeguati al caso d'uso specifico. In particolare, nessuno di essi offre un supporto realmente efficace per documenti contenenti porzioni manoscritte, come ricette mediche o note su pazienti, che costituiscono una parte rilevante della documentazione sanitaria.

In linea teorica, gli OCR basati su tecnologie di intelligenza artificiale sarebbero gli unici in grado di affrontare il carico di lavoro descritto. Tuttavia, la maggior parte delle soluzioni commerciali pi\`u avanzate richiede la trasmissione remota delle pagine da analizzare verso servizi cloud esterni, il che non consente di garantire un controllo completo sulla sicurezza delle informazioni trattate.

Da qui nasce la necessit\`a di disporre di un sistema OCR:
\begin{itemize}[noitemsep]
  \item sufficientemente efficiente da poter essere eseguito interamente in locale;
  \item configurabile e controllabile dagli operatori interni;
  \item adatto a gestire manoscritti in lingua italiana.
\end{itemize}

Fra le possibili alternative, la scelta \`e ricaduta su Kraken, un OCR open source basato su reti neurali profonde, sviluppato originariamente come progetto di ricerca accademica e oggi documentato principalmente sul sito ufficiale \cite{kraken-site} e sulla relativa repository GitHub \cite{kraken-github}. Parte del lavoro su modelli pre‑addestrati e dataset storici \`e stato in passato ospitato anche su archivi istituzionali europei come Zenodo \cite{kraken-zenodo}. Nel tempo, per\`o, alcune di queste risorse sono state spostate o rese non pi\`u direttamente accessibili, rendendo la documentazione complessiva piuttosto frammentata.

\subsection{Input e output del sistema}

Gli \emph{input} del sistema sono le scannerizzazioni dei documenti da digitalizzare, sottoposte preventivamente a un processo di pulizia e normalizzazione tramite ScanTailor (correzione della centratura, ritaglio delle parti non informative, adeguamento del contrasto), mantenendo la risoluzione originale di 600 dpi.

Gli \emph{output} considerati in questo lavoro sono file di testo semplice (\texttt{.txt}) contenenti le trascrizioni delle pagine. Ai fini specifici del progetto, non \`e stato ritenuto necessario ottenere un PDF in cui il testo sia selezionabile e sovrapposto all'immagine: l'obiettivo \`e piuttosto quello di creare, per ciascun documento, un ``pacchetto'' costituito dall'immagine scannerizzata e dalla relativa trascrizione.

Questa organizzazione consente di:
\begin{itemize}[noitemsep]
  \item eseguire ricerche testuali sulle trascrizioni per individuare rapidamente i documenti di interesse;
  \item visualizzare, in caso di necessit\`a, l'immagine originale della pagina, preservando l'aspetto grafico del documento.
\end{itemize}

\section{Architettura del modello}

\subsection{CRNN e LSTM bidirezionali}

Kraken utilizza, per il riconoscimento delle righe di testo, una \emph{Convolutional Recurrent Neural Network} (CRNN) composta da:
\begin{itemize}[noitemsep]
  \item strati convoluzionali (CNN), che estraggono automaticamente caratteristiche locali dall'immagine della riga (contorni, tratti di penna, forme di lettere);
  \item strati ricorrenti LSTM (\emph{Long Short‑Term Memory}) bidirezionali, che modellano le dipendenze sequenziali lungo la riga.
\end{itemize}

L'immagine di una riga viene prima trasformata dalla CNN in una sequenza di vettori di feature
\[
\{\mathbf{f}_1, \mathbf{f}_2, \dots, \mathbf{f}_T\},
\]
dove ogni $\mathbf{f}_t$ riassume le informazioni visive di una ``finestra'' verticale della riga. Questa sequenza viene poi elaborata da strati LSTM bidirezionali: per ogni posizione $t$ la rete calcola uno stato in direzione \emph{forward} (da sinistra a destra) e uno in direzione \emph{backward} (da destra a sinistra). I due stati vengono concatenati, ottenendo una rappresentazione che tiene conto sia del contesto precedente sia di quello successivo.

Le LSTM estendono le RNN classiche introducendo celle di memoria e meccanismi di \emph{gating} (input, output, forget), progettati per mitigare il problema del gradiente che svanisce e consentire la propagazione di informazioni su intervalli temporali pi\`u lunghi. Questo \`e particolarmente utile nel riconoscimento di testo manoscritto, dove l'interpretazione di un carattere pu\`o dipendere fortemente dalle lettere adiacenti (ad esempio per distinguere tra ``m'' e ``rn'').

\subsection{Funzione di costo CTC}

L'uscita della parte ricorrente della rete \`e, per ogni passo temporale $t$, un vettore di
probabilit\`a sui possibili simboli (lettere, numeri, segni di punteggiatura e un simbolo
speciale \emph{blank}). Il problema principale \`e che:
\begin{itemize}[noitemsep]
  \item non \`e noto a priori l'allineamento tra posizioni temporali e caratteri della trascrizione;
  \item la lunghezza della sequenza di output \`e generalmente diversa dalla lunghezza della trascrizione in caratteri.
\end{itemize}

Per gestire questa situazione Kraken utilizza la funzione di costo \emph{Connectionist Temporal Classification} (CTC). L'idea di base \`e la seguente:
\begin{itemize}[noitemsep]
  \item la rete produce una sequenza ``estesa'' di simboli, che pu\`o contenere ripetizioni e simboli \emph{blank};
  \item una procedura di \emph{collasso} elimina i simboli \emph{blank} e comprime le ripetizioni consecutive, ottenendo una sequenza di caratteri ``pulita'';
  \item la CTC definisce l'insieme di tutte le sequenze estese che, dopo il collasso, producono la trascrizione desiderata, e massimizza la probabilit\`a totale di tale insieme.
\end{itemize}

Formalmente, se indichiamo con $\mathbf{y}_t$ la distribuzione di probabilit\`a sui simboli al
tempo $t$ e con $\ell$ la sequenza di caratteri corretta, la CTC definisce la funzione di costo:
\[
\mathcal{L}_{\text{CTC}} = - \log P(\ell \mid \mathbf{y}_1, \dots, \mathbf{y}_T),
\]
dove $P(\ell \mid \mathbf{y}_{1:T})$ \`e la somma delle probabilit\`a di tutte le sequenze
estese che collassano in $\ell$. Il calcolo di questa probabilit\`a avviene tramite un algoritmo
di tipo \emph{forward--backward}, analogo a quello utilizzato nei modelli di Markov nascosti.

In questo modo, durante l'addestramento non \`e necessario fornire un allineamento esplicito
``pixel per carattere'': \`e sufficiente disporre, per ogni immagine di riga, della trascrizione
completa.

\subsection{Decodifica}

In fase di inferenza, dato un output probabilistico per ogni passo temporale, si pu\`o applicare
una decodifica CTC semplice (scegliendo ad ogni passo il simbolo con probabilit\`a massima e
collassando ripetizioni e \emph{blank}) oppure metodi pi\`u sofisticati basati su \emph{beam
search} e, se disponibile, modelli linguistici di supporto.

Nel caso considerato, Kraken utilizza la decodifica CTC per ricostruire la sequenza testuale
a partire dalle distribuzioni di probabilit\`a prodotte dal modello CRNN. Questo approccio
consente di addestrare il modello direttamente su coppie immagine–trascrizione senza richiedere
un allineamento manuale carattere–pixel, ed \`e particolarmente adatto al riconoscimento di
testo manoscritto, dove la segmentazione esplicita dei singoli caratteri \`e spesso ambigua.

\section{Modello di partenza e difficolt\`a di documentazione}

Per l'addestramento \`e stato utilizzato come punto di partenza il modello
\texttt{Tridis\_Medieval\_EarlyModern.mlmodel}, ottenuto tramite il gestore dei modelli incluso
in Kraken. Documentazione e riferimenti storici indicano che questo modello \cite{kraken-zenodo}
\`e stato addestrato su manoscritti latini tardo‑medievali e di et\`a moderna e costituisce una
buona base di partenza per il riconoscimento di grafie storiche europee.

L'informazione secondo cui tale modello risulta adatto anche come punto di partenza per il
riconoscimento di manoscritti italiani deriva in parte da risorse online oggi non pi\`u
direttamente accessibili (ad esempio alcune pagine Zenodo storicamente collegate a Kraken) e in
parte da risposte fornite da strumenti di intelligenza artificiale che citano tali risorse come
fonte. In pratica, la documentazione su modelli e dataset di Kraken risulta distribuita fra:
\begin{itemize}[noitemsep]
  \item il sito ufficiale del progetto \cite{kraken-site};
  \item la repository GitHub \cite{kraken-github};
  \item archivi istituzionali come Zenodo \cite{kraken-zenodo}, in cui per\`o non tutte le
        risorse storiche sono ancora disponibili.
\end{itemize}

Questa frammentazione ha reso necessario un lavoro preliminare di ``ricostruzione'' della
pipeline di addestramento, basato sia sulla documentazione ufficiale, sia su esempi di codice
pubblicamente disponibili, sia sull'esperienza pratica nel configurare l'ambiente.

\section{Metodi}

\subsection{Ambiente di esecuzione}

Dal punto di vista operativo, disponendo di una scheda grafica NVIDIA, \`e stato utilizzato
come sistema operativo Pop\!\_OS, che offre un supporto immediato ai driver proprietari NVIDIA e
all'uso dei CUDA core (nel caso specifico versione 12). In un ambiente \texttt{conda} dedicato
\`e stato installato Kraken tramite \texttt{pip}, insieme alle dipendenze necessarie.

Tutta la logica di preparazione dei dati e gestione dei file di \emph{ground truth} \`e stata
implementata in Python, con l'obiettivo di ottenere uno strato di astrazione riutilizzabile.

\subsection{Gestione delle immagini}

Come base di addestramento sono stati utilizzati circa 150 fogli di documenti, redatti a mano
e gi\`a trascritti in precedenza. I fogli sono stati scannerizzati utilizzando una stampante da
ufficio professionale con risoluzione di 600 dpi.

Le immagini sono state pre‑elaborate con ScanTailor, correggendo:
\begin{itemize}[noitemsep]
  \item la centratura delle pagine;
  \item il ritaglio dei margini non informativi;
  \item il bilanciamento complessivo del contenuto visivo,
\end{itemize}
mantenendo la risoluzione a 600 dpi.

Successivamente, ogni pagina \`e stata suddivisa in singole righe di testo. A ciascuna riga
\`e stata associata la relativa trascrizione manuale, in modo da costruire un dataset di coppie
immagine–testo utilizzabile per il \emph{fine tuning}. La struttura dei file \`e stata organizzata
in cartelle dedicate per le immagini e per i testi, con convenzioni di denominazione coerenti per
facilitare gli abbinamenti automatici.

\subsection{Preparazione del \emph{ground truth} e training}

Le trascrizioni manuali erano conservate in formato Markdown, scelta che rendeva pi\`u agevole la
lettura umana ma richiedeva una fase di pulizia prima di poter essere utilizzate come
\emph{ground truth}. Sono stati quindi sviluppati script Python per:
\begin{itemize}[noitemsep]
  \item estrarre il testo ``pulito'' dai file \texttt{.md};
  \item generare un file \texttt{ground\_truth.txt} nel formato atteso da \texttt{ketos}
        (percorso immagine + trascrizione tab‑separati);
  \item validare e normalizzare il \emph{ground truth};
  \item suddividere i dati in insiemi di training, validation e test;
  \item estrarre il charset effettivamente utilizzato;
  \item produrre file \texttt{.gt.txt} (sidecar) per ogni immagine, contenenti la trascrizione
        associata.
\end{itemize}

Le immagini delle righe sono state ulteriormente normalizzate con \texttt{ImageMagick} per
facilitare la lettura da parte di \texttt{ketos} (deskew, conversione in scala di grigi,
ridimensionamento e centratura all'interno di un riquadro di dimensioni fissate).

Infine, il modello \`e stato addestrato con \texttt{ketos train}, utilizzando il modello
\texttt{Tridis\_Medieval\_EarlyModern.mlmodel} come punto di partenza e specificando gli insiemi
di immagini per training e validation.

\section{Risultati sperimentali}

\subsection{Metrica utilizzata}

Dato che il modello opera riga per riga producendo sequenze di caratteri, la valutazione naturale
sarebbe basata su indicatori quali il \emph{Character Error Rate} (CER) o il \emph{Word Error
Rate} (WER). Nel presente progetto, tuttavia, la metrica pi\`u rilevante per l'utente finale
(l'operatore che utilizza le trascrizioni per la ricerca documentale e per adempiere agli obblighi
normativi) \`e la correttezza delle singole parole.

Per questo motivo si considera la seguente metrica intuitiva:
\[
\text{Accuratezza parole} =
\frac{\text{\# parole riconosciute correttamente}}{\text{\# parole totali}}.
\]

In tutti gli esperimenti ogni prova consiste nel sottoporre al modello un foglio contenente
100 parole manoscritte, e nel contare quante di esse vengono riconosciute correttamente. I
risultati riportati sono calcolati su 20 prove indipendenti per ciascuno scenario e vengono
sintetizzati tramite media e deviazione standard.

\subsection{Scenario 1: stessa calligrafia del training}

Nel primo scenario il modello \`e stato testato su pagine appartenenti agli stessi documenti
utilizzati per il training, quindi:
\begin{itemize}[noitemsep]
  \item stessa persona che ha scritto a mano tutte le pagine;
  \item stessa tipologia di carta e impaginazione;
  \item condizioni di scansione controllate (600 dpi e pre‑elaborazione con ScanTailor).
\end{itemize}

Sono state condotte 20 prove indipendenti. In ciascuna prova il modello ha riconosciuto un foglio
contenente 100 parole, e per ogni foglio \`e stato contato il numero di parole trascritte
correttamente. La media sulle 20 prove risulta pari a:
\[
\text{Accuratezza media} \approx 88\% \pm 2\%,
\]
dove $\pm 2\%$ rappresenta approssimativamente la deviazione standard tra le prove (ossia,
nella maggior parte dei casi, l'accuratezza per singolo foglio ricade nell'intervallo 86–90\%).

Gli errori non comportano quasi mai uno stravolgimento completo della parola, ma consistono
piuttosto in sostituzioni di singole lettere graficamente simili (ad esempio \emph{``casa''}
riconosciuta come \emph{``caso''}). Questi risultati indicano che il \emph{fine tuning} ha
effettivamente permesso al modello di apprendere in maniera soddisfacente la calligrafia
specifica dell'autore dei documenti.

\subsection{Scenario 2: calligrafia diversa}

Nel secondo scenario l'OCR \`e stato applicato a pagine manoscritte da una persona diversa, ma
su fogli con caratteristiche simili (righe prestampate, impaginazione analoga a quella dei
documenti usati in addestramento).

Anche in questo caso sono state condotte 20 prove indipendenti, ciascuna su un foglio contenente
100 parole. La media sulle 20 prove risulta pari a:
\[
\text{Accuratezza media} \approx 61\% \pm 2\%,
\]
cio\`e il modello riconosce correttamente in media 61 parole su 100, con una variabilit\`a tra le
prove di circa due punti percentuali.

L'output rimane comunque leggibile e utile come bozza iniziale, ma la quantit\`a di correzioni
manuali richieste aumenta sensibilmente. Questa diminuzione di prestazioni mette in luce un
aspetto atteso: con un dataset di addestramento relativamente limitato (circa 150 pagine), il
modello tende a specializzarsi sulla calligrafia di riferimento e fatica a generalizzare a
scritture diverse, pur mantenendo una certa capacit\`a di riconoscere la struttura delle parole.

\subsection{Ruolo della qualit\`a di scansione}

Durante i test \`e emerso che una parte consistente delle difficolt\`a non \`e dovuta soltanto
alla calligrafia, ma anche alla qualit\`a della scansione. Pagine acquisite con inclinazione
eccessiva, contrasto basso o sfocatura locale risultano notevolmente pi\`u difficili da
riconoscere, indipendentemente dal contenuto testuale.

Ci\`o suggerisce che, oltre al miglioramento del modello, un elemento cruciale per aumentare
l'accuratezza complessiva \`e il controllo del processo di acquisizione (scelta dello scanner,
impostazioni stabili, eventuale normalizzazione delle immagini prima del riconoscimento).

\subsection{Sintesi dei risultati}

La Tabella~\ref{tab:accuracy_scenari} riassume i risultati principali:

\begin{table}[h]
\centering
\begin{tabular}{@{}l c@{}}
\toprule
Scenario di test & Accuratezza parole (media \(\pm\) dev. std.) \\
\midrule
Stessa persona (documenti di riferimento) & \(88\% \pm 2\%\) \\
Altra persona, stessa tipologia di fogli  & \(61\% \pm 2\%\) \\
\bottomrule
\end{tabular}
\caption{Accuratezza a livello di parola in due scenari di test, calcolata su 20 prove indipendenti per scenario (100 parole per prova).}
\label{tab:accuracy_scenari}
\end{table}

\begin{figure}[h]
\centering
\begin{tikzpicture}
\begin{axis}[
    ybar,
    ymin=0,ymax=100,
    bar width=18pt,
    enlarge x limits=0.35,
    ylabel={Accuratezza parole (\%)},
    symbolic x coords={Stessa persona,Altra persona},
    xtick=data,
    nodes near coords,
    nodes near coords align={vertical},
    width=0.9\columnwidth,
    height=0.55\textheight,
    ylabel style={font=\small},
    tick label style={font=\small},
]
\addplot coordinates {
    (Stessa persona, 88)
    (Altra persona, 61)
};
\end{axis}
\end{tikzpicture}
\caption{Accuratezza media a livello di parola nei due scenari di test considerati (20 prove da 100 parole ciascuna per scenario).}
\label{fig:accuracy_bar}
\end{figure}

\begin{figure}[h]
\centering
\begin{tikzpicture}
\begin{axis}[
    xlabel={Numero di pagine annotate per il training},
    ylabel={Accuratezza parole (\%)},
    xmin=0, xmax=1050,
    ymin=60, ymax=100,
    xtick={0,50,100,150,300,1000},
    ytick={60,70,80,90,100},
    width=0.9\columnwidth,
    height=0.55\textheight,
    grid=both,
    grid style={gray!20},
    tick label style={font=\small},
    xlabel style={font=\small},
    ylabel style={font=\small},
]
\addplot[
    color=FireBrick,
    mark=*,
    thick
] coordinates {
    (50, 75)
    (100, 83)
    (150, 88)
    (300, 92)
    (1000, 95)
};
\end{axis}
\end{tikzpicture}
\caption{Andamento qualitativo atteso dell'accuratezza a livello di parola al crescere del numero di pagine annotate utilizzate per il training. Il punto a 150 pagine corrisponde ai risultati effettivamente ottenuti; gli altri valori sono stime indicative.}
\label{fig:accuracy_vs_pages}
\end{figure}

\section{Conclusioni}

I risultati ottenuti indicano che il modello fine‑tunato rappresenta una prima base operativa per
l'introduzione di un OCR per manoscritti italiani all'interno dell'INRCA. Nel caso della
calligrafia specifica utilizzata per l'addestramento, il sistema raggiunge un'accuratezza a
livello di parola prossima al 90\%, consentendo di ridurre in modo sensibile il tempo necessario
per produrre trascrizioni utilizzabili.

Tuttavia, il modello non \`e ancora sufficientemente robusto da poter essere impiegato in maniera
completamente automatica sulla documentazione clinica reale. In particolare:
\begin{itemize}[noitemsep]
  \item la generalizzazione a scritture di persone diverse risulta ancora limitata (circa il 61\% di parole corrette, con una deviazione standard di 2\%);
  \item la qualit\`a della scansione influisce in maniera significativa sui risultati;
  \item permane la necessit\`a di una supervisione umana per la correzione degli errori.
\end{itemize}

Nonostante questi limiti, il lavoro dimostra la fattibilit\`a tecnica di uno strumento OCR
specializzato, eseguibile interamente in locale e potenzialmente integrabile nei flussi
documentali dell'istituto. Ci\`o costituisce un elemento importante per motivare la richiesta
di fondi dedicati allo sviluppo di una soluzione pi\`u completa e matura.

\subsection{Sviluppi futuri}

Per rendere il sistema sufficientemente affidabile in ambito produttivo saranno necessari ulteriori passaggi:
\begin{itemize}[noitemsep]
  \item aumentare significativamente il numero di pagine annotate, passando dalle circa 150 attuali ad almeno un ordine di grandezza superiore (nell'ordine delle mille pagine), in modo da migliorare la capacit\`a di generalizzazione del modello;
  \item coinvolgere il DPO aziendale per definire un protocollo di selezione, anonimizzazione e utilizzo di un campione rappresentativo di documenti clinici reali;
  \item rafforzare la pipeline di acquisizione delle immagini, standardizzando il processo di scansione e le operazioni di pre‑elaborazione;
  \item valutare l'introduzione di un modulo di post‑processing linguistico (ad esempio un correttore contestuale) che possa correggere automaticamente gli errori pi\`u frequenti sulla base del lessico e del contesto.
\end{itemize}

In prospettiva, il lavoro svolto costituisce un primo tassello concreto verso la realizzazione di
uno strumento OCR conforme sia alle esigenze operative sia agli obblighi normativi in materia di
protezione dei dati e conservazione della documentazione storica.

\printbibliography

\end{document}